{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cd0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1468bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for your local API\n",
    "BASE_URL = \"http://localhost:9999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4193093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. List all models\n",
    "def list_models():\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/models\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34fd471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'qwen3:0.6b',\n",
       "   'model': 'qwen3:0.6b',\n",
       "   'modified_at': '2025-06-23T12:01:06.5218042Z',\n",
       "   'size': 522653767,\n",
       "   'digest': '7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen3',\n",
       "    'families': ['qwen3'],\n",
       "    'parameter_size': '751.63M',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'qwen2.5:0.5b',\n",
       "   'model': 'qwen2.5:0.5b',\n",
       "   'modified_at': '2025-06-23T11:41:01.5026019Z',\n",
       "   'size': 397821319,\n",
       "   'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen2',\n",
       "    'families': ['qwen2'],\n",
       "    'parameter_size': '494.03M',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'qwen2.5:7b',\n",
       "   'model': 'qwen2.5:7b',\n",
       "   'modified_at': '2025-06-23T08:37:36.0484171Z',\n",
       "   'size': 4683087332,\n",
       "   'digest': '845dbda0ea48ed749caafd9e6037047aa19acfcfd82e704d7ca97d631a0b697e',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen2',\n",
       "    'families': ['qwen2'],\n",
       "    'parameter_size': '7.6B',\n",
       "    'quantization_level': 'Q4_K_M'}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate text\n",
    "def generate_text(model_name, prompt):\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/generate\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa136e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'qwen2.5:0.5b',\n",
       " 'created_at': '2025-06-23T12:13:21.981794241Z',\n",
       " 'response': 'Bu cümle \"selamlar dünya\" anlamına gelir. İngilizce cümleyi Türkçe\\'de şu şekilde ifade edebilir: \"Gümler bir dünyadır.\" Bu nedenle, \"Selamlar\" (çünkü kalitesiz) ve \"dünya\" (görüşmeleri veya insanlarla yaşanan bilgileri, yani \"dışyalar\" anlamına gelir.) ile ifade edilebilir. Türkçe cümlelerin genel yapısı şunları içerir: \\n\\n- \"Selamlar\" - kalitesiz / nüfusli \\n- \"dünya\" - insanlarla yaşanan bilgiler\\n\\nBu nedenle, cümleyi daha etik ve doğal bir şekilde ifade etmek için, \"Gümler bir dünyadır.\" veya \"Çünkü kalitesiz / nüfusli, insanlarla yaşanan bilgileri var\" gibi konuları kullanmak gerekir. Bu konuda, \"çünkü\" (özellikle \"çünkü\") ile ifade edin.',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [151644,\n",
       "  8948,\n",
       "  198,\n",
       "  2610,\n",
       "  525,\n",
       "  1207,\n",
       "  16948,\n",
       "  11,\n",
       "  3465,\n",
       "  553,\n",
       "  54364,\n",
       "  14817,\n",
       "  13,\n",
       "  1446,\n",
       "  525,\n",
       "  264,\n",
       "  10950,\n",
       "  17847,\n",
       "  13,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  9507,\n",
       "  9467,\n",
       "  277,\n",
       "  129463,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198,\n",
       "  59808,\n",
       "  143990,\n",
       "  330,\n",
       "  9507,\n",
       "  9467,\n",
       "  277,\n",
       "  129463,\n",
       "  1,\n",
       "  137511,\n",
       "  63466,\n",
       "  17837,\n",
       "  404,\n",
       "  13,\n",
       "  38421,\n",
       "  968,\n",
       "  321,\n",
       "  449,\n",
       "  346,\n",
       "  143989,\n",
       "  3179,\n",
       "  72,\n",
       "  136891,\n",
       "  4172,\n",
       "  68,\n",
       "  129607,\n",
       "  128813,\n",
       "  421,\n",
       "  1021,\n",
       "  1578,\n",
       "  3065,\n",
       "  321,\n",
       "  404,\n",
       "  25,\n",
       "  330,\n",
       "  38,\n",
       "  2391,\n",
       "  1014,\n",
       "  261,\n",
       "  15248,\n",
       "  139704,\n",
       "  329,\n",
       "  29233,\n",
       "  1189,\n",
       "  27227,\n",
       "  308,\n",
       "  14134,\n",
       "  273,\n",
       "  11,\n",
       "  330,\n",
       "  39041,\n",
       "  9467,\n",
       "  277,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  127529,\n",
       "  35354,\n",
       "  3611,\n",
       "  449,\n",
       "  8,\n",
       "  5208,\n",
       "  330,\n",
       "  126427,\n",
       "  22891,\n",
       "  1,\n",
       "  320,\n",
       "  70,\n",
       "  9416,\n",
       "  124911,\n",
       "  76,\n",
       "  7865,\n",
       "  72,\n",
       "  86959,\n",
       "  61538,\n",
       "  13796,\n",
       "  4260,\n",
       "  83568,\n",
       "  28618,\n",
       "  20316,\n",
       "  70,\n",
       "  5769,\n",
       "  72,\n",
       "  11,\n",
       "  379,\n",
       "  5559,\n",
       "  330,\n",
       "  67,\n",
       "  32473,\n",
       "  88,\n",
       "  7934,\n",
       "  1,\n",
       "  137511,\n",
       "  63466,\n",
       "  17837,\n",
       "  404,\n",
       "  6138,\n",
       "  30805,\n",
       "  421,\n",
       "  1021,\n",
       "  1578,\n",
       "  457,\n",
       "  48838,\n",
       "  404,\n",
       "  13,\n",
       "  136891,\n",
       "  143990,\n",
       "  1536,\n",
       "  258,\n",
       "  4081,\n",
       "  301,\n",
       "  39428,\n",
       "  89413,\n",
       "  22066,\n",
       "  359,\n",
       "  45837,\n",
       "  127051,\n",
       "  404,\n",
       "  25,\n",
       "  4710,\n",
       "  12,\n",
       "  330,\n",
       "  39041,\n",
       "  9467,\n",
       "  277,\n",
       "  1,\n",
       "  481,\n",
       "  35354,\n",
       "  3611,\n",
       "  449,\n",
       "  608,\n",
       "  308,\n",
       "  2391,\n",
       "  69,\n",
       "  355,\n",
       "  742,\n",
       "  715,\n",
       "  12,\n",
       "  330,\n",
       "  126427,\n",
       "  22891,\n",
       "  1,\n",
       "  481,\n",
       "  61538,\n",
       "  13796,\n",
       "  4260,\n",
       "  83568,\n",
       "  28618,\n",
       "  20316,\n",
       "  70,\n",
       "  5769,\n",
       "  271,\n",
       "  59808,\n",
       "  308,\n",
       "  14134,\n",
       "  273,\n",
       "  11,\n",
       "  143989,\n",
       "  3179,\n",
       "  72,\n",
       "  61494,\n",
       "  1842,\n",
       "  1579,\n",
       "  5208,\n",
       "  136317,\n",
       "  15248,\n",
       "  128813,\n",
       "  421,\n",
       "  1021,\n",
       "  1842,\n",
       "  73753,\n",
       "  33171,\n",
       "  11,\n",
       "  330,\n",
       "  38,\n",
       "  2391,\n",
       "  1014,\n",
       "  261,\n",
       "  15248,\n",
       "  139704,\n",
       "  329,\n",
       "  29233,\n",
       "  1189,\n",
       "  86959,\n",
       "  330,\n",
       "  45913,\n",
       "  127529,\n",
       "  35354,\n",
       "  3611,\n",
       "  449,\n",
       "  608,\n",
       "  308,\n",
       "  2391,\n",
       "  69,\n",
       "  355,\n",
       "  742,\n",
       "  11,\n",
       "  61538,\n",
       "  13796,\n",
       "  4260,\n",
       "  83568,\n",
       "  28618,\n",
       "  20316,\n",
       "  70,\n",
       "  5769,\n",
       "  72,\n",
       "  762,\n",
       "  1,\n",
       "  67845,\n",
       "  16540,\n",
       "  1276,\n",
       "  3777,\n",
       "  57016,\n",
       "  48562,\n",
       "  342,\n",
       "  27626,\n",
       "  404,\n",
       "  13,\n",
       "  27227,\n",
       "  16540,\n",
       "  8053,\n",
       "  11,\n",
       "  330,\n",
       "  3131,\n",
       "  127529,\n",
       "  1,\n",
       "  320,\n",
       "  2956,\n",
       "  125961,\n",
       "  273,\n",
       "  330,\n",
       "  3131,\n",
       "  127529,\n",
       "  899,\n",
       "  30805,\n",
       "  421,\n",
       "  1021,\n",
       "  1578,\n",
       "  258,\n",
       "  13],\n",
       " 'total_duration': 2885355005,\n",
       " 'load_duration': 167846028,\n",
       " 'prompt_eval_count': 33,\n",
       " 'prompt_eval_duration': 40637298,\n",
       " 'eval_count': 240,\n",
       " 'eval_duration': 2676303397}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"qwen2.5:0.5b\", \"selamlar dünya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce46642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pull new models\n",
    "def pull_model(model_name):\n",
    "    try:\n",
    "        payload = {\"name\": model_name}  # Changed from \"model\" to \"name\"\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/pull\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error pulling model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5841b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_model(\"qwen3:0.6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f55012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Delete models\n",
    "def delete_model(model_name):\n",
    "    try:\n",
    "        response = requests.delete(f\"{BASE_URL}/models/{model_name}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e91987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Health check\n",
    "def health_check():\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/health\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error checking health: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05b0de57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'healthy'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da4a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check:\n",
      "{'status': 'healthy'}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Available Models:\n",
      "{'models': [{'name': 'qwen3:0.6b', 'model': 'qwen3:0.6b', 'modified_at': '2025-06-23T12:13:20.328938Z', 'size': 522653767, 'digest': '7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen3', 'families': ['qwen3'], 'parameter_size': '751.63M', 'quantization_level': 'Q4_K_M'}}, {'name': 'qwen2.5:0.5b', 'model': 'qwen2.5:0.5b', 'modified_at': '2025-06-23T11:41:01.5026019Z', 'size': 397821319, 'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_K_M'}}, {'name': 'qwen2.5:7b', 'model': 'qwen2.5:7b', 'modified_at': '2025-06-23T08:37:36.0484171Z', 'size': 4683087332, 'digest': '845dbda0ea48ed749caafd9e6037047aa19acfcfd82e704d7ca97d631a0b697e', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '7.6B', 'quantization_level': 'Q4_K_M'}}]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Generating Text:\n",
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-23T12:13:24.238173726Z', 'response': \"In the vast ocean of technology,\\nDocker is like a mastermind,\\nCrafting the blueprint for your application's codebase,\\nSafeguarding it from the sea of chaos.\\n\\nWith a single command, you can deploy your applications,\\nFrom the cloud to the edge, no matter where they're meant to be,\\nTaming the storm with Docker containers,\\nA tool that is all around, in any place.\", 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 7985, 264, 2805, 32794, 911, 40549, 23853, 151645, 198, 151644, 77091, 198, 641, 279, 12767, 17951, 315, 5440, 345, 35, 13659, 374, 1075, 264, 7341, 37724, 345, 38849, 287, 279, 52929, 369, 697, 3766, 594, 2038, 3152, 345, 50, 2577, 81871, 287, 432, 504, 279, 9396, 315, 26915, 382, 2354, 264, 3175, 3210, 11, 498, 646, 10517, 697, 8357, 345, 3830, 279, 9437, 311, 279, 6821, 11, 902, 4925, 1380, 807, 2299, 8791, 311, 387, 345, 51, 6469, 279, 13458, 448, 40549, 23853, 345, 32, 5392, 429, 374, 678, 2163, 11, 304, 894, 1992, 13], 'total_duration': 1066491890, 'load_duration': 126516798, 'prompt_eval_count': 36, 'prompt_eval_duration': 44469155, 'eval_count': 84, 'eval_duration': 894879733}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if API is healthy\n",
    "    print(\"Health Check:\")\n",
    "    health = health_check()\n",
    "    print(health)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # List available models\n",
    "    print(\"Available Models:\")\n",
    "    models = list_models()\n",
    "    print(models)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Generate text with a model\n",
    "    print(\"Generating Text:\")\n",
    "    result = generate_text(\"qwen2.5:0.5b\", \"Write a short poem about Docker containers\")\n",
    "    print(result)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Example of pulling a model (uncomment if needed)\n",
    "    # print(\"Pulling Model:\")\n",
    "    # pull_result = pull_model(\"qwen2.5:0.5b\")\n",
    "    # print(pull_result)\n",
    "    \n",
    "    # Example of deleting a model (uncomment if needed)\n",
    "    # print(\"Deleting Model:\")\n",
    "    # delete_result = delete_model(\"model_name_to_delete\")\n",
    "    # print(delete_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85cbe18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-23T12:13:24.623761691Z', 'response': 'In the heart of AI,\\nData flows like molten metal,\\nMachine learns.', 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 7985, 264, 6386, 38242, 911, 5662, 6832, 151645, 198, 151644, 77091, 198, 641, 279, 4746, 315, 15235, 345, 1043, 27455, 1075, 21609, 1960, 9317, 345, 21605, 46210, 13], 'total_duration': 369296422, 'load_duration': 169014394, 'prompt_eval_count': 36, 'prompt_eval_duration': 38063054, 'eval_count': 17, 'eval_duration': 161707498}\n"
     ]
    }
   ],
   "source": [
    "# In another cell - generate text\n",
    "poem = generate_text(\"qwen2.5:0.5b\", \"Write a haiku about machine learning\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26bc283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Generate text with chat template format\n",
    "def generate_chat(model_name, messages):\n",
    "    \"\"\"\n",
    "    Generate text using chat message format\n",
    "    messages: list of dicts with 'role' and 'content' keys\n",
    "    Example: [{\"role\":\"system\", \"content\":\"You are helpful\"}, {\"role\":\"user\", \"content\":\"Hello!\"}]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert chat messages to a formatted prompt\n",
    "        formatted_prompt = format_chat_messages(messages)\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": formatted_prompt\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/generate\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating chat: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_chat_messages(messages):\n",
    "    \"\"\"Convert chat messages to a single formatted prompt string\"\"\"\n",
    "    formatted_parts = []\n",
    "    \n",
    "    for message in messages:\n",
    "        role = message.get(\"role\", \"\")\n",
    "        content = message.get(\"content\", \"\")\n",
    "        \n",
    "        if role == \"system\":\n",
    "            formatted_parts.append(f\"System: {content}\")\n",
    "        elif role == \"user\":\n",
    "            formatted_parts.append(f\"User: {content}\")\n",
    "        elif role == \"assistant\":\n",
    "            formatted_parts.append(f\"Assistant: {content}\")\n",
    "        else:\n",
    "            formatted_parts.append(f\"{role.title()}: {content}\")\n",
    "    \n",
    "    # Join with double newlines and add assistant prompt\n",
    "    formatted_prompt = \"\\n\\n\".join(formatted_parts) + \"\\n\\nAssistant:\"\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "656bb672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-23T12:13:24.961082397Z', 'response': 'Hello! How can I assist you today?', 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 2320, 25, 1446, 525, 264, 10950, 17847, 271, 1474, 25, 21927, 12853, 2219, 71703, 25, 151645, 198, 151644, 77091, 198, 9707, 0, 2585, 646, 358, 7789, 498, 3351, 30], 'total_duration': 312406078, 'load_duration': 134383976, 'prompt_eval_count': 44, 'prompt_eval_duration': 76437580, 'eval_count': 10, 'eval_duration': 100977720}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple chat\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello Chat!\"}\n",
    "]\n",
    "response = generate_chat(\"qwen2.5:0.5b\", messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
