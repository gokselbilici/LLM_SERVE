{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3cd0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1468bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for your local API\n",
    "BASE_URL = \"http://localhost:9999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4193093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. List all models\n",
    "def list_models():\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/models\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error listing models: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e34fd471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'qwen3:0.6b',\n",
       "   'model': 'qwen3:0.6b',\n",
       "   'modified_at': '2025-06-23T12:13:20.328938Z',\n",
       "   'size': 522653767,\n",
       "   'digest': '7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen3',\n",
       "    'families': ['qwen3'],\n",
       "    'parameter_size': '751.63M',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'qwen2.5:0.5b',\n",
       "   'model': 'qwen2.5:0.5b',\n",
       "   'modified_at': '2025-06-23T11:41:01.5026019Z',\n",
       "   'size': 397821319,\n",
       "   'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen2',\n",
       "    'families': ['qwen2'],\n",
       "    'parameter_size': '494.03M',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'qwen2.5:7b',\n",
       "   'model': 'qwen2.5:7b',\n",
       "   'modified_at': '2025-06-23T08:37:36.0484171Z',\n",
       "   'size': 4683087332,\n",
       "   'digest': '845dbda0ea48ed749caafd9e6037047aa19acfcfd82e704d7ca97d631a0b697e',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'qwen2',\n",
       "    'families': ['qwen2'],\n",
       "    'parameter_size': '7.6B',\n",
       "    'quantization_level': 'Q4_K_M'}}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "994a19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate text\n",
    "def generate_text(model_name, prompt):\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/generate\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating text: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa136e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'qwen2.5:0.5b',\n",
       " 'created_at': '2025-06-24T11:44:18.591215513Z',\n",
       " 'response': '\"Selamalar dünya\" di olarak da bulunabilir ve bu konuda daha fazla bilgi verirken yardımcı olabilirim. Ancak, en popüler ve yaygın olarak kullanılan \"Selamalar dünya\" dilinde, \"Salam\" (çesil) ile \"Salam\" (çesil) olarak kullanılır ve her ne kadar eski, ancak etrafında yer almış oyunlarda çok sık görünen bir konu.\\n\\nYani, \"selamalar\" (çesil) ve \"salama\" (çesil) gibi belirsizlerdir. Bu oyun, her bir iki konuyumun üzerinde farklı kılacaklar arasında olacak şekilde, \"yazıcı\" (çesil) olan sesi veya \"yazıkça\" olan tarihsel bir süre boyunca aktif olduğunu gösterir. Ancak, bu oyun, aynı zamanda bazı özel durumlarda bulunabilir ve bu durumlar genellikle \"kızıl ve ciddi\" konu ile ilişkilidir.\\n\\nHerhangi bir konuyu seçerseniz, size daha fazla bilgi verirmelisiniz. Bu konuda daha detaylı bilgiler yapmak veya dikkatli oyunları oluşturmak için yardım istemiyorsunuz.',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'context': [151644,\n",
       "  8948,\n",
       "  198,\n",
       "  2610,\n",
       "  525,\n",
       "  1207,\n",
       "  16948,\n",
       "  11,\n",
       "  3465,\n",
       "  553,\n",
       "  54364,\n",
       "  14817,\n",
       "  13,\n",
       "  1446,\n",
       "  525,\n",
       "  264,\n",
       "  10950,\n",
       "  17847,\n",
       "  13,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  9507,\n",
       "  9467,\n",
       "  277,\n",
       "  129463,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198,\n",
       "  1,\n",
       "  39041,\n",
       "  309,\n",
       "  7934,\n",
       "  129463,\n",
       "  1,\n",
       "  1853,\n",
       "  49894,\n",
       "  2994,\n",
       "  140373,\n",
       "  81758,\n",
       "  5208,\n",
       "  1031,\n",
       "  16540,\n",
       "  8053,\n",
       "  61494,\n",
       "  37069,\n",
       "  4260,\n",
       "  20316,\n",
       "  8212,\n",
       "  2739,\n",
       "  404,\n",
       "  2712,\n",
       "  133346,\n",
       "  8328,\n",
       "  12762,\n",
       "  61372,\n",
       "  13,\n",
       "  30277,\n",
       "  585,\n",
       "  11,\n",
       "  662,\n",
       "  2420,\n",
       "  92071,\n",
       "  5208,\n",
       "  143840,\n",
       "  49894,\n",
       "  138287,\n",
       "  330,\n",
       "  39041,\n",
       "  309,\n",
       "  7934,\n",
       "  129463,\n",
       "  1,\n",
       "  18840,\n",
       "  26976,\n",
       "  11,\n",
       "  330,\n",
       "  50,\n",
       "  16823,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  288,\n",
       "  321,\n",
       "  8,\n",
       "  30805,\n",
       "  330,\n",
       "  50,\n",
       "  16823,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  288,\n",
       "  321,\n",
       "  8,\n",
       "  49894,\n",
       "  57016,\n",
       "  127654,\n",
       "  5208,\n",
       "  1059,\n",
       "  834,\n",
       "  73909,\n",
       "  1531,\n",
       "  6642,\n",
       "  11,\n",
       "  45745,\n",
       "  585,\n",
       "  1842,\n",
       "  15453,\n",
       "  38697,\n",
       "  54195,\n",
       "  89484,\n",
       "  32473,\n",
       "  297,\n",
       "  42420,\n",
       "  75,\n",
       "  71526,\n",
       "  57012,\n",
       "  126998,\n",
       "  133037,\n",
       "  12495,\n",
       "  15248,\n",
       "  16540,\n",
       "  84,\n",
       "  382,\n",
       "  56,\n",
       "  5559,\n",
       "  11,\n",
       "  330,\n",
       "  9507,\n",
       "  309,\n",
       "  7934,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  288,\n",
       "  321,\n",
       "  8,\n",
       "  5208,\n",
       "  330,\n",
       "  19222,\n",
       "  3029,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  288,\n",
       "  321,\n",
       "  8,\n",
       "  67845,\n",
       "  1656,\n",
       "  16838,\n",
       "  449,\n",
       "  1536,\n",
       "  3741,\n",
       "  13,\n",
       "  27227,\n",
       "  297,\n",
       "  42420,\n",
       "  11,\n",
       "  1059,\n",
       "  15248,\n",
       "  600,\n",
       "  6642,\n",
       "  16540,\n",
       "  4076,\n",
       "  372,\n",
       "  359,\n",
       "  129947,\n",
       "  129370,\n",
       "  595,\n",
       "  54788,\n",
       "  78665,\n",
       "  13796,\n",
       "  129010,\n",
       "  8328,\n",
       "  78665,\n",
       "  128813,\n",
       "  11,\n",
       "  330,\n",
       "  88,\n",
       "  1370,\n",
       "  85554,\n",
       "  1,\n",
       "  320,\n",
       "  3131,\n",
       "  288,\n",
       "  321,\n",
       "  8,\n",
       "  56298,\n",
       "  15537,\n",
       "  72,\n",
       "  86959,\n",
       "  330,\n",
       "  88,\n",
       "  1370,\n",
       "  40890,\n",
       "  17472,\n",
       "  1,\n",
       "  56298,\n",
       "  259,\n",
       "  2780,\n",
       "  4997,\n",
       "  301,\n",
       "  15248,\n",
       "  126369,\n",
       "  8171,\n",
       "  359,\n",
       "  924,\n",
       "  22318,\n",
       "  333,\n",
       "  128776,\n",
       "  128689,\n",
       "  404,\n",
       "  13,\n",
       "  30277,\n",
       "  585,\n",
       "  11,\n",
       "  1031,\n",
       "  297,\n",
       "  42420,\n",
       "  11,\n",
       "  129301,\n",
       "  60476,\n",
       "  9817,\n",
       "  130330,\n",
       "  129485,\n",
       "  10651,\n",
       "  42231,\n",
       "  71526,\n",
       "  140373,\n",
       "  81758,\n",
       "  5208,\n",
       "  1031,\n",
       "  10651,\n",
       "  372,\n",
       "  13796,\n",
       "  4081,\n",
       "  613,\n",
       "  1579,\n",
       "  273,\n",
       "  330,\n",
       "  74,\n",
       "  47880,\n",
       "  54788,\n",
       "  5208,\n",
       "  272,\n",
       "  1772,\n",
       "  72,\n",
       "  1,\n",
       "  16540,\n",
       "  84,\n",
       "  30805,\n",
       "  127253,\n",
       "  85526,\n",
       "  307,\n",
       "  404,\n",
       "  382,\n",
       "  20705,\n",
       "  20658,\n",
       "  72,\n",
       "  15248,\n",
       "  16540,\n",
       "  4076,\n",
       "  84,\n",
       "  125312,\n",
       "  87989,\n",
       "  449,\n",
       "  11,\n",
       "  1379,\n",
       "  61494,\n",
       "  37069,\n",
       "  4260,\n",
       "  20316,\n",
       "  8212,\n",
       "  2739,\n",
       "  2853,\n",
       "  301,\n",
       "  57404,\n",
       "  449,\n",
       "  13,\n",
       "  27227,\n",
       "  16540,\n",
       "  8053,\n",
       "  61494,\n",
       "  3392,\n",
       "  352,\n",
       "  25611,\n",
       "  20316,\n",
       "  70,\n",
       "  5769,\n",
       "  39428,\n",
       "  48562,\n",
       "  86959,\n",
       "  294,\n",
       "  29887,\n",
       "  266,\n",
       "  742,\n",
       "  297,\n",
       "  42420,\n",
       "  45837,\n",
       "  127080,\n",
       "  48562,\n",
       "  33171,\n",
       "  132874,\n",
       "  5999,\n",
       "  336,\n",
       "  16220,\n",
       "  1087,\n",
       "  359,\n",
       "  5197,\n",
       "  13],\n",
       " 'total_duration': 7327733017,\n",
       " 'load_duration': 3768056820,\n",
       " 'prompt_eval_count': 33,\n",
       " 'prompt_eval_duration': 128684057,\n",
       " 'eval_count': 283,\n",
       " 'eval_duration': 3430114722}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"qwen2.5:0.5b\", \"selamlar dünya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ce46642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pull new models\n",
    "def pull_model(model_name):\n",
    "    try:\n",
    "        payload = {\"name\": model_name}  # Changed from \"model\" to \"name\"\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/pull\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error pulling model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5841b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_model(\"qwen3:0.6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f55012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Delete models\n",
    "def delete_model(model_name):\n",
    "    try:\n",
    "        response = requests.delete(f\"{BASE_URL}/models/{model_name}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e91987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Health check\n",
    "def health_check():\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/health\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error checking health: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b0de57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'healthy'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0da4a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check:\n",
      "{'status': 'healthy'}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Available Models:\n",
      "{'models': [{'name': 'qwen3:0.6b', 'model': 'qwen3:0.6b', 'modified_at': '2025-06-24T11:44:19.5901923Z', 'size': 522653767, 'digest': '7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen3', 'families': ['qwen3'], 'parameter_size': '751.63M', 'quantization_level': 'Q4_K_M'}}, {'name': 'qwen2.5:0.5b', 'model': 'qwen2.5:0.5b', 'modified_at': '2025-06-23T11:41:01.5026019Z', 'size': 397821319, 'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_K_M'}}, {'name': 'qwen2.5:7b', 'model': 'qwen2.5:7b', 'modified_at': '2025-06-23T08:37:36.0484171Z', 'size': 4683087332, 'digest': '845dbda0ea48ed749caafd9e6037047aa19acfcfd82e704d7ca97d631a0b697e', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '7.6B', 'quantization_level': 'Q4_K_M'}}]}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Generating Text:\n",
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-24T11:44:21.494451351Z', 'response': \"In the vast expanse of the cloud,\\nDocker's code glows, its power true.\\nA container, a small, yet mighty,\\nIs it not a living soul?\\n\\nThrough the pipes and connections tight,\\nA blueprint is made, a plan divine,\\nEach image built anew each time,\\nA testament to code that flows.\\n\\nIn the hands of many developers,\\nA world is born, from containers grow,\\nEach application unique,\\nA community's love for software grows.\\n\\nSo let Docker shine on,\\nWith its heart and soul, it will endure,\\nFor in this space we find\\nA way to move so much in one place.\", 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 7985, 264, 2805, 32794, 911, 40549, 23853, 151645, 198, 151644, 77091, 198, 641, 279, 12767, 505, 94419, 315, 279, 9437, 345, 35, 13659, 594, 2038, 2770, 4241, 11, 1181, 2355, 830, 624, 32, 5476, 11, 264, 2613, 11, 3602, 41627, 345, 3872, 432, 537, 264, 5382, 13527, 1939, 23857, 279, 31175, 323, 13234, 10296, 345, 32, 52929, 374, 1865, 11, 264, 3119, 29367, 345, 4854, 2168, 5798, 92292, 1817, 882, 345, 32, 60200, 311, 2038, 429, 27455, 382, 641, 279, 6078, 315, 1657, 13402, 345, 32, 1879, 374, 9223, 11, 504, 23853, 3063, 345, 4854, 3766, 4911, 345, 32, 3942, 594, 2948, 369, 3162, 27715, 382, 4416, 1077, 40549, 32405, 389, 345, 2354, 1181, 4746, 323, 13527, 11, 432, 686, 45653, 345, 2461, 304, 419, 3550, 582, 1477, 198, 32, 1616, 311, 3271, 773, 1753, 304, 825, 1992, 13], 'total_duration': 1742845014, 'load_duration': 119331680, 'prompt_eval_count': 36, 'prompt_eval_duration': 51945878, 'eval_count': 128, 'eval_duration': 1570991137}\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if API is healthy\n",
    "    print(\"Health Check:\")\n",
    "    health = health_check()\n",
    "    print(health)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # List available models\n",
    "    print(\"Available Models:\")\n",
    "    models = list_models()\n",
    "    print(models)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Generate text with a model\n",
    "    print(\"Generating Text:\")\n",
    "    result = generate_text(\"qwen2.5:0.5b\", \"Write a short poem about Docker containers\")\n",
    "    print(result)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Example of pulling a model (uncomment if needed)\n",
    "    # print(\"Pulling Model:\")\n",
    "    # pull_result = pull_model(\"qwen2.5:0.5b\")\n",
    "    # print(pull_result)\n",
    "    \n",
    "    # Example of deleting a model (uncomment if needed)\n",
    "    # print(\"Deleting Model:\")\n",
    "    # delete_result = delete_model(\"model_name_to_delete\")\n",
    "    # print(delete_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85cbe18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-24T11:44:21.928934131Z', 'response': \"In data's warm embrace,\\nAlgorithms dance on the screen,\\nLearning never stops.\", 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 7985, 264, 6386, 38242, 911, 5662, 6832, 151645, 198, 151644, 77091, 198, 641, 821, 594, 8205, 26732, 345, 2101, 18980, 15254, 389, 279, 4171, 345, 47467, 2581, 17933, 13], 'total_duration': 417758048, 'load_duration': 167955630, 'prompt_eval_count': 36, 'prompt_eval_duration': 42801694, 'eval_count': 18, 'eval_duration': 206462822}\n"
     ]
    }
   ],
   "source": [
    "# In another cell - generate text\n",
    "poem = generate_text(\"qwen2.5:0.5b\", \"Write a haiku about machine learning\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26bc283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Generate text with chat template format\n",
    "def generate_chat(model_name, messages):\n",
    "    \"\"\"\n",
    "    Generate text using chat message format\n",
    "    messages: list of dicts with 'role' and 'content' keys\n",
    "    Example: [{\"role\":\"system\", \"content\":\"You are helpful\"}, {\"role\":\"user\", \"content\":\"Hello!\"}]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert chat messages to a formatted prompt\n",
    "        formatted_prompt = format_chat_messages(messages)\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": formatted_prompt\n",
    "        }\n",
    "        response = requests.post(\n",
    "            f\"{BASE_URL}/generate\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error generating chat: {e}\")\n",
    "        return None\n",
    "\n",
    "def format_chat_messages(messages):\n",
    "    \"\"\"Convert chat messages to a single formatted prompt string\"\"\"\n",
    "    formatted_parts = []\n",
    "    \n",
    "    for message in messages:\n",
    "        role = message.get(\"role\", \"\")\n",
    "        content = message.get(\"content\", \"\")\n",
    "        \n",
    "        if role == \"system\":\n",
    "            formatted_parts.append(f\"System: {content}\")\n",
    "        elif role == \"user\":\n",
    "            formatted_parts.append(f\"User: {content}\")\n",
    "        elif role == \"assistant\":\n",
    "            formatted_parts.append(f\"Assistant: {content}\")\n",
    "        else:\n",
    "            formatted_parts.append(f\"{role.title()}: {content}\")\n",
    "    \n",
    "    # Join with double newlines and add assistant prompt\n",
    "    formatted_prompt = \"\\n\\n\".join(formatted_parts) + \"\\n\\nAssistant:\"\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "656bb672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'qwen2.5:0.5b', 'created_at': '2025-06-24T11:44:22.305982859Z', 'response': 'Hello! How can I assist you today?', 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 2320, 25, 1446, 525, 264, 10950, 17847, 271, 1474, 25, 21927, 12853, 2219, 71703, 25, 151645, 198, 151644, 77091, 198, 9707, 0, 2585, 646, 358, 7789, 498, 3351, 30], 'total_duration': 351410273, 'load_duration': 160370041, 'prompt_eval_count': 44, 'prompt_eval_duration': 83944502, 'eval_count': 10, 'eval_duration': 106464056}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Simple chat\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello Chat!\"}\n",
    "]\n",
    "response = generate_chat(\"qwen2.5:0.5b\", messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
